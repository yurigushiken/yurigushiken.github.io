---
layout: post
title: "LCN Video Comparison: Multi-Video Synchronization Tool"
date: 2025-03-18 10:00:00 -0400
categories: tools development
---

This is a **double post** for progress in our Infant Event Representations study at the [Language and Cognitive Neuroscience Lab](https://www.tc.columbia.edu/lcl/), at Teachers College.

We (1) created heatmaps that represent all participant gazepoints (2) and developed a specialized data visualization website for the Language and Cognition Lab at Columbia University. The [LCN Video Comparison Tool](https://yurigushiken.github.io/LCN-video-viewer/) helps us compare multiple experimental videos simultaneously with frame-by-frame precision.

<iframe width="100%" height="400" src="https://www.youtube.com/embed/LjDz26i2shU" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
*(1) Heatmap video, 11-month old participants, GW event*

![LCN Video Comparison Tool Screenshot](/media/eir-data-visualization.png)
*(2) Data representation tool: [link](https://yurigushiken.github.io/LCN-video-viewer/)*

The tool solves a common research problem: comparing participants' responses side by side. Frame-precise synchronization reveals subtle behavioral patterns that would otherwise remain hidden in sequential viewing.

Capabilities:
- Customizable grid layouts (1Ã—1, 1Ã—2, 2Ã—2, 2Ã—3)
- Synchronized playback of multiple videos
- Frame-by-frame navigation (1/30th of a second precision)
- Leader video designation that others follow
- Precise frame jumping/scrubbing across all videos

This project reflects my commitment to and interest in multiple means of data representation, aligning with Universal Design for Learning (UDL) principles in education.
